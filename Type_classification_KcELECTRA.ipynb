{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kelly790/.conda/envs/torch/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import numpy as np\n",
    "from typing import Optional, Sequence\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, f1_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from torch.nn import functional as F\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from transformers import Trainer, TrainingArguments, AutoModelForSequenceClassification, AutoTokenizer, EarlyStoppingCallback, AutoModel, AutoConfig\n",
    "\n",
    "import gc\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:1')\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyperparameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'EPOCHS': 10,\n",
    "    'LEARNING_RATE':1e-4,\n",
    "    'BATCH_SIZE': 256,\n",
    "    'SEED':42\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fixed randomseed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/kelly790/dacon 연습/문장분류/train.csv')\n",
    "test = pd.read_csv('/home/kelly790/dacon 연습/문장분류/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>문장</th>\n",
       "      <th>유형</th>\n",
       "      <th>극성</th>\n",
       "      <th>시제</th>\n",
       "      <th>확실성</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.75%포인트 금리 인상은 1994년 이후 28년 만에 처음이다.</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>현재</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이어 ＂앞으로 전문가들과 함께 4주 단위로 상황을 재평가할 예정＂이라며 ＂그 이전이...</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>과거</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>정부가 고유가 대응을 위해 7월부터 연말까지 유류세 인하 폭을 30%에서 37%까지...</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>미래</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-미래-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>서울시는 올해 3월 즉시 견인 유예시간 60분을 제공하겠다고 밝혔지만, 하루 만에 ...</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>과거</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>익사한 자는 사다리에 태워 거꾸로 놓고 소금으로 코를 막아 가득 채운다.</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>현재</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16536</th>\n",
       "      <td>＇신동덤＇은 ＇신비한 동물사전＇과 ＇해리 포터＇ 시리즈를 잇는 마법 어드벤처물로, ...</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>과거</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16537</th>\n",
       "      <td>수족냉증은 어릴 때부터 심했으며 관절은 어디 한 곳이 아니고 목, 어깨, 팔꿈치, ...</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>과거</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16538</th>\n",
       "      <td>김금희 소설가는 ＂계약서 조정이 그리 어려운가 작가를 격려한다면서 그런 문구 하나 ...</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>과거</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16539</th>\n",
       "      <td>1만명이 넘는 방문자수를 기록한 이번 전시회는 총 77개 작품을 넥슨 사옥을 그대로...</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>과거</td>\n",
       "      <td>불확실</td>\n",
       "      <td>사실형-긍정-과거-불확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16540</th>\n",
       "      <td>《목민심서》의 내용이다.</td>\n",
       "      <td>사실형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>현재</td>\n",
       "      <td>확실</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16541 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      문장   유형  극성  시제  확실성  \\\n",
       "0                  0.75%포인트 금리 인상은 1994년 이후 28년 만에 처음이다.  사실형  긍정  현재   확실   \n",
       "1      이어 ＂앞으로 전문가들과 함께 4주 단위로 상황을 재평가할 예정＂이라며 ＂그 이전이...  사실형  긍정  과거   확실   \n",
       "2      정부가 고유가 대응을 위해 7월부터 연말까지 유류세 인하 폭을 30%에서 37%까지...  사실형  긍정  미래   확실   \n",
       "3      서울시는 올해 3월 즉시 견인 유예시간 60분을 제공하겠다고 밝혔지만, 하루 만에 ...  사실형  긍정  과거   확실   \n",
       "4               익사한 자는 사다리에 태워 거꾸로 놓고 소금으로 코를 막아 가득 채운다.  사실형  긍정  현재   확실   \n",
       "...                                                  ...  ...  ..  ..  ...   \n",
       "16536  ＇신동덤＇은 ＇신비한 동물사전＇과 ＇해리 포터＇ 시리즈를 잇는 마법 어드벤처물로, ...  사실형  긍정  과거   확실   \n",
       "16537  수족냉증은 어릴 때부터 심했으며 관절은 어디 한 곳이 아니고 목, 어깨, 팔꿈치, ...  사실형  긍정  과거   확실   \n",
       "16538  김금희 소설가는 ＂계약서 조정이 그리 어려운가 작가를 격려한다면서 그런 문구 하나 ...  사실형  긍정  과거   확실   \n",
       "16539  1만명이 넘는 방문자수를 기록한 이번 전시회는 총 77개 작품을 넥슨 사옥을 그대로...  사실형  긍정  과거  불확실   \n",
       "16540                                      《목민심서》의 내용이다.  사실형  긍정  현재   확실   \n",
       "\n",
       "               label  \n",
       "0       사실형-긍정-현재-확실  \n",
       "1       사실형-긍정-과거-확실  \n",
       "2       사실형-긍정-미래-확실  \n",
       "3       사실형-긍정-과거-확실  \n",
       "4       사실형-긍정-현재-확실  \n",
       "...              ...  \n",
       "16536   사실형-긍정-과거-확실  \n",
       "16537   사실형-긍정-과거-확실  \n",
       "16538   사실형-긍정-과거-확실  \n",
       "16539  사실형-긍정-과거-불확실  \n",
       "16540   사실형-긍정-현재-확실  \n",
       "\n",
       "[16541 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['ID'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>문장</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>장욱진의 ＇가족＇은 허물 없는 가족애를, 처음 공개되는 정약용의 ＇정효자전＇과 ＇정...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>조지 W 부시, 버락 오바마 전 대통령도 전쟁 위험 때문에 버린 카드다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>지난해 1분기 128억원이었던 영업이익이 올해 1분기 505억원으로 급증했다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>수상 작가와 맺으려던 계약서 내용 가운데 일부가 ＇독소 조항＇으로 해석돼 수정을 요...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>결국 최근 KDB산업은행은 대규모 손실 위기에 닥친 에어부산에 140억원 금융지원을...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7085</th>\n",
       "      <td>2020 세계국가편람 모바일 앱은 세계 216개국의 국가개황과 주요 경제지표, 사회...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7086</th>\n",
       "      <td>탈세계화 징후들이 반갑지 않은 이유다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7087</th>\n",
       "      <td>틱톡은 6월 ＇인터넷 안전의 달＇을 맞아 올바른 개인정보 보호 관리 방법, 앱 내 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7088</th>\n",
       "      <td>만약 3개월 간 채굴자들의 투표를 거쳐 2/3 이상의 해시파워가 ＇채굴세＇ 도입에 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7089</th>\n",
       "      <td>아버지 홍언필이 인기척에 깨 그 광경을 지켜봤다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7090 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     문장\n",
       "0     장욱진의 ＇가족＇은 허물 없는 가족애를, 처음 공개되는 정약용의 ＇정효자전＇과 ＇정...\n",
       "1              조지 W 부시, 버락 오바마 전 대통령도 전쟁 위험 때문에 버린 카드다.\n",
       "2           지난해 1분기 128억원이었던 영업이익이 올해 1분기 505억원으로 급증했다.\n",
       "3     수상 작가와 맺으려던 계약서 내용 가운데 일부가 ＇독소 조항＇으로 해석돼 수정을 요...\n",
       "4     결국 최근 KDB산업은행은 대규모 손실 위기에 닥친 에어부산에 140억원 금융지원을...\n",
       "...                                                 ...\n",
       "7085  2020 세계국가편람 모바일 앱은 세계 216개국의 국가개황과 주요 경제지표, 사회...\n",
       "7086                              탈세계화 징후들이 반갑지 않은 이유다.\n",
       "7087  틱톡은 6월 ＇인터넷 안전의 달＇을 맞아 올바른 개인정보 보호 관리 방법, 앱 내 ...\n",
       "7088  만약 3개월 간 채굴자들의 투표를 거쳐 2/3 이상의 해시파워가 ＇채굴세＇ 도입에 ...\n",
       "7089                        아버지 홍언필이 인기척에 깨 그 광경을 지켜봤다.\n",
       "\n",
       "[7090 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test.drop(['ID'], axis=1)\n",
    "test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None): # 데이터셋 전처리 \n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx): # 데이터셋에서 특정 1개의 샘플을 가져오는 함수\n",
    "        item = {key: torch.tensor(val[idx]) for key,val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            st_type = self.labels['type'][idx]\n",
    "            st_polarity = self.labels['polarity'][idx]\n",
    "            st_tense = self.labels['tense'][idx]\n",
    "            st_certainty = self.labels['certainty'][idx]\n",
    "            item[\"labels\"] = torch.tensor(st_type), torch.tensor(st_polarity), torch.tensor(st_tense), torch.tensor(st_certainty)\n",
    "        return item\n",
    "\n",
    "    def __len__(self): # 데이터셋 길이. 즉, 총 샘플의 수를 적는 부분\n",
    "        return len(self.encodings[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define trainer\n",
    "from transformers import Trainer\n",
    "class CustomTrainer(Trainer): # 모델 학습부터 평가까지 한 번에 해결하는 API\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        # forward pass\n",
    "        labels = inputs.pop(\"labels\").to(torch.int64)\n",
    "        \n",
    "        type_logit, polarity_logit, tense_logit, certainty_logit = model(**inputs)\n",
    "        \n",
    "        # # simple loss\n",
    "        # criterion = {\n",
    "        #     'type' : nn.CrossEntropyLoss().to(device),\n",
    "        #     'polarity' : nn.CrossEntropyLoss().to(device),\n",
    "        #     'tense' : nn.CrossEntropyLoss().to(device),\n",
    "        #     'certainty' : nn.CrossEntropyLoss().to(device)\n",
    "        # }\n",
    "        # loss = criterion['type'](type_logit, labels[::, 0]) + \\\n",
    "        #             criterion['polarity'](polarity_logit, labels[::, 1]) + \\\n",
    "        #             criterion['tense'](tense_logit,labels[::, 2]) + \\\n",
    "        #             criterion['certainty'](certainty_logit, labels[::, 3])\n",
    "        \n",
    "        # focal loss\n",
    "        criterion = {\n",
    "            'type' : FocalLoss().to(device),\n",
    "            'polarity' : FocalLoss().to(device),\n",
    "            'tense' : FocalLoss().to(device),\n",
    "            'certainty' : FocalLoss().to(device)\n",
    "        }\n",
    "        # labels = labels.type(torch.float).clone().detach()\n",
    "        loss = criterion['type'](type_logit, labels[::, 0]) + \\\n",
    "                    criterion['polarity'](polarity_logit, labels[::, 1]) + \\\n",
    "                    criterion['tense'](tense_logit, labels[::, 2]) + \\\n",
    "                    criterion['certainty'](certainty_logit, labels[::, 3])\n",
    "\n",
    "        outputs = None, \\\n",
    "                    torch.argmax(type_logit, dim = 1), \\\n",
    "                    torch.argmax(polarity_logit, dim = 1),\\\n",
    "                    torch.argmax(tense_logit, dim = 1),\\\n",
    "                    torch.argmax(certainty_logit, dim = 1)\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "유형 = LabelEncoder()\n",
    "유형.fit(train['유형'])\n",
    "\n",
    "극성 = LabelEncoder()\n",
    "극성.fit(train['극성'])\n",
    "\n",
    "시제 = LabelEncoder()\n",
    "시제.fit(train['시제'])\n",
    "\n",
    "확실성 = LabelEncoder()\n",
    "확실성.fit(train['확실성'])\n",
    "\n",
    "def encoding(X_train, X_val):\n",
    "    X_train['유형'] = 유형.transform(X_train['유형'])\n",
    "    X_val['유형'] = 유형.transform(X_val['유형'])\n",
    "\n",
    "    X_train['극성'] = 극성.transform(X_train['극성'])\n",
    "    X_val['극성'] = 극성.transform(X_val['극성'])\n",
    "\n",
    "    X_train['시제'] = 시제.transform(X_train['시제'])\n",
    "    X_val['시제'] = 시제.transform(X_val['시제'])\n",
    "\n",
    "    X_train['확실성'] = 확실성.transform(X_train['확실성'])\n",
    "    X_val['확실성'] = 확실성.transform(X_val['확실성'])\n",
    "\n",
    "    train_labels = {\n",
    "        'type' : X_train['유형'].values,\n",
    "        'polarity' : X_train['극성'].values,\n",
    "        'tense' : X_train['시제'].values,\n",
    "        'certainty' : X_train['확실성'].values\n",
    "    }\n",
    "\n",
    "    val_labels = {\n",
    "        'type' : X_val['유형'].values,\n",
    "        'polarity' : X_val['극성'].values,\n",
    "        'tense' : X_val['시제'].values,\n",
    "        'certainty' : X_val['확실성'].values\n",
    "    }\n",
    "    return train_labels, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recent_file(path):\n",
    "    file_name_and_time_lst = []\n",
    "    # 해당 경로에 있는 파일들의 생성시간을 함께 리스트로 넣어줌. \n",
    "    for f_name in os.listdir(f\"{path}\"):\n",
    "        written_time = os.path.getctime(f\"{path}/{f_name}\")\n",
    "        file_name_and_time_lst.append((f_name, written_time))\n",
    "    # 생성시간 역순으로 정렬하고, \n",
    "    sorted_file_lst = sorted(file_name_and_time_lst, key=lambda x: x[1], reverse=True)\n",
    "    # 가장 앞에 이는 놈을 넣어준다.\n",
    "    recent_file = sorted_file_lst[0]\n",
    "    recent_file_name = recent_file[0]\n",
    "    return f\"{path}/{recent_file_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at beomi/KcELECTRA-base-v2022 were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 7090\n",
      "  Batch size = 2048\n",
      "/tmp/ipykernel_394540/2131821896.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key,val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file pytorch_model.bin from cache at /home/kelly790/.cache/huggingface/hub/models--beomi--KcELECTRA-base-v2022/snapshots/4431b6c7ad00f82fd50880864574cef97e0a368b/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at beomi/KcELECTRA-base-v2022 were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of ElectraModel were initialized from the model checkpoint at beomi/KcELECTRA-base-v2022.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraModel for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 7090\n",
      "  Batch size = 2048\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file pytorch_model.bin from cache at /home/kelly790/.cache/huggingface/hub/models--beomi--KcELECTRA-base-v2022/snapshots/4431b6c7ad00f82fd50880864574cef97e0a368b/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at beomi/KcELECTRA-base-v2022 were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of ElectraModel were initialized from the model checkpoint at beomi/KcELECTRA-base-v2022.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraModel for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 7090\n",
      "  Batch size = 2048\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file pytorch_model.bin from cache at /home/kelly790/.cache/huggingface/hub/models--beomi--KcELECTRA-base-v2022/snapshots/4431b6c7ad00f82fd50880864574cef97e0a368b/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at beomi/KcELECTRA-base-v2022 were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of ElectraModel were initialized from the model checkpoint at beomi/KcELECTRA-base-v2022.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraModel for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 7090\n",
      "  Batch size = 2048\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file pytorch_model.bin from cache at /home/kelly790/.cache/huggingface/hub/models--beomi--KcELECTRA-base-v2022/snapshots/4431b6c7ad00f82fd50880864574cef97e0a368b/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at beomi/KcELECTRA-base-v2022 were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of ElectraModel were initialized from the model checkpoint at beomi/KcELECTRA-base-v2022.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraModel for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 7090\n",
      "  Batch size = 2048\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# KcELECTRA\n",
    "device = torch.device(\"cuda\")\n",
    "model_path = \"beomi/KcELECTRA-base-v2022\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "length = train['문장'].str.len().max()\n",
    "config=AutoConfig.from_pretrained(model_path)\n",
    "config._name_or_path = 'kr.kim'\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        if model_path == 'monologg/kobigbird-bert-base':\n",
    "            config.attention_type = \"original_full\"\n",
    "        self.base_model = AutoModel.from_pretrained(model_path, config=config)\n",
    "        try:\n",
    "            self.out = self.base_model.encoder.layer[-1].output.dense.out_features\n",
    "        except:\n",
    "            self.out = 768\n",
    "        # self.linear = nn.Linear(768, 768//2)\n",
    "\n",
    "        self.type_classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=self.out, out_features=4),\n",
    "        )\n",
    "        self.polarity_classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=self.out, out_features=3),\n",
    "        )\n",
    "        self.tense_classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=self.out, out_features=3),\n",
    "        )\n",
    "        self.certainty_classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=self.out, out_features=2),\n",
    "        )\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, labels=None, token_type_ids=None):\n",
    "        x = self.base_model(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
    "        # x = self.linear(x)\n",
    "        # 문장 유형, 극성, 시제, 확실성을 각각 분류\n",
    "        type_output = self.type_classifier(x[:,0,:].view(-1,self.out))\n",
    "        polarity_output = self.polarity_classifier(x[:,0,:].view(-1,self.out))\n",
    "        tense_output = self.tense_classifier(x[:,0,:].view(-1,self.out))\n",
    "        certainty_output = self.certainty_classifier(x[:,0,:].view(-1,self.out))\n",
    "        return type_output, polarity_output, tense_output, certainty_output\n",
    "\n",
    "gc.collect() # python 자원 관리 \n",
    "torch.cuda.empty_cache() # gpu 자원관리\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "tokenized = tokenizer(test.문장.tolist(), padding=True, truncation=True, max_length=length, return_tensors=\"pt\")\n",
    "test_dataset = CustomDataset(tokenized, None)\n",
    "test_args = TrainingArguments(\n",
    "    output_dir = './',\n",
    "    do_train = False,\n",
    "    do_predict = True,\n",
    "    per_device_eval_batch_size = 256,   \n",
    "    dataloader_drop_last = False    \n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(5):\n",
    "        print(f'Round {i}')\n",
    "        # model = AutoModel.from_pretrained(recent_file('custom_model'), config=config)\n",
    "        model = CustomModel().to(device)\n",
    "        #model.load_state_dict(torch.load(f'/home/kelly790/dacon 연습/문장분류/model'))\n",
    "        torch.save(model, f\"/home/kelly790/dacon 연습/문장분류/model/KcELECTRA.pt\")\n",
    "        trainer = CustomTrainer(\n",
    "                      model = model, \n",
    "                      args = test_args,)\n",
    "        test_results.append(trainer.predict(test_dataset))\n",
    "        del model\n",
    "        del trainer\n",
    "        gc.collect() # python 자원 관리 \n",
    "        torch.cuda.empty_cache() # gpu 자원관리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['유형'] = list(map(lambda x : 유형.inverse_transform([np.argmax(x)]), sum(list(map(lambda x: x.predictions[0], test_results)))/len(test_results)))\n",
    "test['극성'] = list(map(lambda x : 극성.inverse_transform([np.argmax(x)]), sum(list(map(lambda x: x.predictions[1], test_results)))/len(test_results)))\n",
    "test['시제'] = list(map(lambda x : 시제.inverse_transform([np.argmax(x)]), sum(list(map(lambda x: x.predictions[2], test_results)))/len(test_results)))\n",
    "test['확실성'] = list(map(lambda x : 확실성.inverse_transform([np.argmax(x)]), sum(list(map(lambda x: x.predictions[3], test_results)))/len(test_results)))\n",
    "\n",
    "test['유형'] = list(map(lambda x : x[0], test['유형']))\n",
    "test['극성'] = list(map(lambda x : x[0], test['극성']))\n",
    "test['시제'] = list(map(lambda x : x[0], test['시제']))\n",
    "test['확실성'] = list(map(lambda x : x[0], test['확실성']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>문장</th>\n",
       "      <th>유형</th>\n",
       "      <th>극성</th>\n",
       "      <th>시제</th>\n",
       "      <th>확실성</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>장욱진의 ＇가족＇은 허물 없는 가족애를, 처음 공개되는 정약용의 ＇정효자전＇과 ＇정...</td>\n",
       "      <td>대화형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>현재</td>\n",
       "      <td>확실</td>\n",
       "      <td>대화형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>조지 W 부시, 버락 오바마 전 대통령도 전쟁 위험 때문에 버린 카드다.</td>\n",
       "      <td>대화형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>현재</td>\n",
       "      <td>확실</td>\n",
       "      <td>대화형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>지난해 1분기 128억원이었던 영업이익이 올해 1분기 505억원으로 급증했다.</td>\n",
       "      <td>예측형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>현재</td>\n",
       "      <td>확실</td>\n",
       "      <td>예측형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>수상 작가와 맺으려던 계약서 내용 가운데 일부가 ＇독소 조항＇으로 해석돼 수정을 요...</td>\n",
       "      <td>예측형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>현재</td>\n",
       "      <td>확실</td>\n",
       "      <td>예측형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>결국 최근 KDB산업은행은 대규모 손실 위기에 닥친 에어부산에 140억원 금융지원을...</td>\n",
       "      <td>예측형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>현재</td>\n",
       "      <td>확실</td>\n",
       "      <td>예측형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7085</th>\n",
       "      <td>2020 세계국가편람 모바일 앱은 세계 216개국의 국가개황과 주요 경제지표, 사회...</td>\n",
       "      <td>예측형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>현재</td>\n",
       "      <td>확실</td>\n",
       "      <td>예측형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7086</th>\n",
       "      <td>탈세계화 징후들이 반갑지 않은 이유다.</td>\n",
       "      <td>추론형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>현재</td>\n",
       "      <td>불확실</td>\n",
       "      <td>추론형-긍정-현재-불확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7087</th>\n",
       "      <td>틱톡은 6월 ＇인터넷 안전의 달＇을 맞아 올바른 개인정보 보호 관리 방법, 앱 내 ...</td>\n",
       "      <td>예측형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>현재</td>\n",
       "      <td>확실</td>\n",
       "      <td>예측형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7088</th>\n",
       "      <td>만약 3개월 간 채굴자들의 투표를 거쳐 2/3 이상의 해시파워가 ＇채굴세＇ 도입에 ...</td>\n",
       "      <td>예측형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>현재</td>\n",
       "      <td>확실</td>\n",
       "      <td>예측형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7089</th>\n",
       "      <td>아버지 홍언필이 인기척에 깨 그 광경을 지켜봤다.</td>\n",
       "      <td>대화형</td>\n",
       "      <td>긍정</td>\n",
       "      <td>현재</td>\n",
       "      <td>확실</td>\n",
       "      <td>대화형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7090 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     문장   유형  극성  시제  확실성  \\\n",
       "0     장욱진의 ＇가족＇은 허물 없는 가족애를, 처음 공개되는 정약용의 ＇정효자전＇과 ＇정...  대화형  긍정  현재   확실   \n",
       "1              조지 W 부시, 버락 오바마 전 대통령도 전쟁 위험 때문에 버린 카드다.  대화형  긍정  현재   확실   \n",
       "2           지난해 1분기 128억원이었던 영업이익이 올해 1분기 505억원으로 급증했다.  예측형  긍정  현재   확실   \n",
       "3     수상 작가와 맺으려던 계약서 내용 가운데 일부가 ＇독소 조항＇으로 해석돼 수정을 요...  예측형  긍정  현재   확실   \n",
       "4     결국 최근 KDB산업은행은 대규모 손실 위기에 닥친 에어부산에 140억원 금융지원을...  예측형  긍정  현재   확실   \n",
       "...                                                 ...  ...  ..  ..  ...   \n",
       "7085  2020 세계국가편람 모바일 앱은 세계 216개국의 국가개황과 주요 경제지표, 사회...  예측형  긍정  현재   확실   \n",
       "7086                              탈세계화 징후들이 반갑지 않은 이유다.  추론형  긍정  현재  불확실   \n",
       "7087  틱톡은 6월 ＇인터넷 안전의 달＇을 맞아 올바른 개인정보 보호 관리 방법, 앱 내 ...  예측형  긍정  현재   확실   \n",
       "7088  만약 3개월 간 채굴자들의 투표를 거쳐 2/3 이상의 해시파워가 ＇채굴세＇ 도입에 ...  예측형  긍정  현재   확실   \n",
       "7089                        아버지 홍언필이 인기척에 깨 그 광경을 지켜봤다.  대화형  긍정  현재   확실   \n",
       "\n",
       "              label  \n",
       "0      대화형-긍정-현재-확실  \n",
       "1      대화형-긍정-현재-확실  \n",
       "2      예측형-긍정-현재-확실  \n",
       "3      예측형-긍정-현재-확실  \n",
       "4      예측형-긍정-현재-확실  \n",
       "...             ...  \n",
       "7085   예측형-긍정-현재-확실  \n",
       "7086  추론형-긍정-현재-불확실  \n",
       "7087   예측형-긍정-현재-확실  \n",
       "7088   예측형-긍정-현재-확실  \n",
       "7089   대화형-긍정-현재-확실  \n",
       "\n",
       "[7090 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "test['label'] = test['유형'] + '-' + test['극성'] + '-' + test['시제'] + '-' + test['확실성']\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "492527acb83a23147d10ea222e8b25a5f747a0f75be240338053b95d77080704"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
